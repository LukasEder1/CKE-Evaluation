{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32ae771",
   "metadata": {},
   "source": [
    "# Collection of usefulls Functions / Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98bf2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from policy_processing import *\n",
    "from cleantext import clean\n",
    "import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk.stem import *\n",
    "import news_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "455c5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/home/lukas/Documents/semester6/NLP/newsEdits/datasets/small10k.sqlite')\n",
    "df = pd.read_sql(\"SELECT * FROM small10k\", con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad4cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_func = lambda text : clean(text,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=False,                     # lowercase text\n",
    "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=False,                  # replace all URLs with a special token\n",
    "    no_emails=False,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "    no_numbers=False,               # replace all numbers with a special token\n",
    "    no_digits=False,                # replace all digits with a special token\n",
    "    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "    no_punct=False,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587af883",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [90536,\n",
    " 90344,\n",
    " 98640,\n",
    " 98585,\n",
    " 99880,\n",
    " 108079,\n",
    " 90555,\n",
    " 90545,\n",
    " 98553,\n",
    " 98572,\n",
    " 98659,\n",
    " 98706,\n",
    " 108052,\n",
    " 108097,\n",
    " 100541,\n",
    " 108771,\n",
    " 2435,\n",
    " 100595,\n",
    " 108778,\n",
    " 100419,\n",
    " 108438,\n",
    " 108835,\n",
    " 106348,\n",
    " 106486,\n",
    " 90041,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4928f37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f736b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = {\n",
    "    \"90536\": [\"TRUSTe's\",\n",
    "            \"European Union\", \"day trial\",\n",
    "            \"personally identifiable\", \"personally\", \"Salesforce\",\n",
    "            \"identifiable information\", \"testimonial\", \"gifs\"\n",
    "            \"version\", \"Third Party\", \"clear gifs\", \"web beacons\",\n",
    "            \"service providers\", \"email\"],\n",
    "\n",
    "\n",
    "    \"90344\": [\"Telerik\", \"May\", \"Progress Software\", \"software\", \"web\", \"site\",\n",
    "         \"community progress\", \"Telerik Analytics\",\n",
    "        \"provider\", \"service providers\", \"geo-location\", \"ads\", \"Google\",\n",
    "         \"google Analytics\", \"web sites\", \"information\", \"children\"],\n",
    "\n",
    "\n",
    "    \"98640\": [\"validation page\", \"scripts\", \"HTML5\", \"tools\", \"management tools\", \"management\",\n",
    "         \"various\", \"various browsers\", \"removing\", \"transparency\", \"may offer\"],   \n",
    "\n",
    "\n",
    "    \"98585\": [\"center\", \"center cloud\", \"cloud console\", \"security center\", \"console\", \"cloud\",\n",
    "          \"solution\", \"onedrive\", \"web beacons\"], \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"99880\": [\"science\", \"reproductive science\", \"Michele Abbott\", \"Michele\", \"Abbott\"\n",
    "    \"electronic\", \"health information\", \"insurance company\", \"health\"],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"108079\": [\"Insights\", \"viva\",\"club\",\"sydney\",\"Viva Sydney\",\"Sydney Club\", \"visitors\", \"large\"], \n",
    "\n",
    "\n",
    "\n",
    "    \"90555\":  [\"ads\", \"google\", \"use\", \"privacy policy\", \"policy\", \"privacy\", \"data\", \"data control\"],\n",
    "\n",
    "\n",
    "    \"90545\":  [\"Yahoo\", \"Privacy Policy\", \"AOL\", \"Oath\", \"choices\", \"your choices\",\n",
    "          \"privacy\", \"oath privacy\"],\n",
    "\n",
    "\n",
    "\n",
    "    \"98553\": [\"April\", \"2016\", \"affiliated websites\", \"providers\", \"billing information\",\n",
    "    \"over-the-phone\", \"advertisements\", \"plans\", \"partners\"], \n",
    "\n",
    "\n",
    "    \"98572\": [\"job applications\", \"Privacy Shield\", \"Shield Framework\", \"framework\", \"shield\",\n",
    "          \"secure data\", \"data recovery\",  \"Truste\"],\n",
    "\n",
    "\n",
    "\n",
    "    \"98659\": [\"affiliated entities\", \"TOS\", \"without limitation\",\n",
    "    \"Seed Spark\", \"speed\", \"spark\", \"liable\" ,\"opt\",\"opt out\", \"google\",\n",
    "          \"remarketing\",\"updated\",  \"California\", \"vendors\"],\n",
    "\n",
    "\n",
    "    \"98706\": [\"Australian\", \"Learning\", \"online advertising\", \"New Zealand\", \"United States\",\n",
    "           \"America\",  \"Melbourne\", \"contact us\", \"contact\"],\n",
    "\n",
    "\n",
    "    \"108052\":  [\"Reloaded\", \"Reloaded Games\", \"games\", \"K2\", \"K2 network\", \"January\"],\n",
    "\n",
    "\n",
    "    \"108097\": [\"Website Security\", \"PKI solutions\", \"DigiCert\", \"DigiCert Inc\" \"MySymantec\",  \"Global\",\n",
    "            \"transfers\",\n",
    "            \"approved partners\", \"service providers\", \"contractors\", \"around the world\"], \n",
    "\n",
    "\n",
    "    100541: [\"live\", \"browse history\", \"Synchrony Bank\", \"Synchrony\", \"GE money\", \"money bank\", \"GEMB\",\n",
    "         \"Credit Card\", \"Fair Credit\", \"Billing Act\"],\n",
    "\n",
    "    108771: [\"tap\", \"ALTERNATIVE PRESS LLC\", \"alternative\", \"press\", \"llc\", \"alternative press\", \"press llc\"],\n",
    "\n",
    "    2435: [\"properties\", \"sites\", \"requests\", \"california\", \"545\", \"5215\", \"john\", \"carpenter\", \"freeway\", \n",
    "        \"john carpenter\" ,\"700\", \"1400\", \"Connor\", \"Blvd\", \"Connor Blvd\"],\n",
    "\n",
    "    100595: [\"evine\", \"shopnbc\", \"ge money\", \"synchrony\", \"mobile\", \"mobile device\", \"money bank\", \"Synchrony Bank\",\n",
    "         \"california\", \"TLS\"],\n",
    "\n",
    "    108778: [\"DART\", \"DART cookie\", \"parties\", \"third party\", \"email\"], # email is written differently \n",
    "    100419: [\"toxic shock\", \"toxic\", \"shock\", \"shockya\", \"advertising\", \"third-party\", \"DART\",\n",
    "         \"web\", \"site\", \"ads\"],\n",
    "\n",
    "\n",
    "\n",
    "    108438: [\"TakeLessons\", \"profile\", \"public\", \"updates\", \"changes\", \"unsubscribe\"], \n",
    "\n",
    "    108835: [\"personally identifiable\", \" identifiable information\", \"cookies\", \"use\", \"personally\",\n",
    "             \"identifiable\"],\n",
    "\n",
    "    # small change examples\n",
    "    106348: [\"advertising\", \"www\", \"targeted\", \"partner\", \"ad network\", \"ad\", \"network\"],\n",
    "    90041: [\"mobile\", \"mobile app\", \"app\", \"may\"],\n",
    "    106486: [\"google\", \"cookies\", \"13\", \"Crosby St\", \"Hollywood\", \"895\", \"use\", \"opt\"]\n",
    "          \n",
    "          \n",
    "          \n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4593d",
   "metadata": {},
   "source": [
    "# Create Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab7e8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>IoU</th>\n",
       "      <th>#overlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90344</td>\n",
       "      <td>0.435556</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98585</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99880</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>108079</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90545</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>98553</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98572</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Site        F1  Precision    Recall       IoU  #overlaps\n",
       "0   90536  0.000000   0.000000  0.000000  0.000000          0\n",
       "1   90344  0.435556   0.466667  0.466667  0.333333          7\n",
       "2   98640  0.000000   0.000000  0.000000  0.000000          0\n",
       "3   98585  0.035556   0.133333  0.133333  0.071429          2\n",
       "4   99880  0.533333   0.533333  0.533333  0.363636          8\n",
       "5  108079  0.320000   0.400000  0.400000  0.250000          6\n",
       "6   90555  0.000000   0.000000  0.000000  0.000000          0\n",
       "7   90545  0.080000   0.200000  0.200000  0.111111          3\n",
       "8   98553  0.320000   0.400000  0.400000  0.272727          6\n",
       "9   98572  0.008889   0.066667  0.066667  0.034483          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary.extensive_summary(ids, \n",
    "                          show_results=True, \n",
    "                          k=15,\n",
    "                          name_a = f\"standard_pipeline_keywords\", \n",
    "                          name_b = f\"standard_baseline1_keywords\",\n",
    "                          save_prefix=f\"standard_\", \n",
    "                          path='dataframes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb3a616",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'summaries/theshold_k_0_baseline1_summary_furthest_90536_99878.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c681174d867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#summaries05 = pd.read_csv(f\"summaries/new1_summary_furthest_106917_4207.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummaries01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"summaries/theshold_k_0_baseline1_summary_furthest_90536_99878.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msummaries02\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"summaries/theshold_k_0_baseline2_summary_furthest_90536_99878.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msummaries11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"summaries/theshold_k_1_baseline1_summary_furthest_90536_99878.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msummaries12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"summaries/theshold_k_1_baseline2_summary_furthest_90536_99878.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'summaries/theshold_k_0_baseline1_summary_furthest_90536_99878.csv'"
     ]
    }
   ],
   "source": [
    "#summaries05 = pd.read_csv(f\"summaries/new1_summary_furthest_106917_4207.csv\")\n",
    "summaries01 = pd.read_csv(f\"summaries/theshold_k_0_baseline1_summary_furthest_90536_99878.csv\")\n",
    "summaries02 = pd.read_csv(f\"summaries/theshold_k_0_baseline2_summary_furthest_90536_99878.csv\")\n",
    "summaries11 = pd.read_csv(f\"summaries/theshold_k_1_baseline1_summary_furthest_90536_99878.csv\")\n",
    "summaries12 = pd.read_csv(f\"summaries/theshold_k_1_baseline2_summary_furthest_90536_99878.csv\")\n",
    "summaries21 = pd.read_csv(f\"summaries/theshold_k_2_baseline1_summary_furthest_90536_99878.csv\")\n",
    "summaries22 = pd.read_csv(f\"summaries/theshold_k_2_baseline2_summary_furthest_90536_99878.csv\")\n",
    "summaries31 = pd.read_csv(f\"summaries/theshold_k_3_baseline1_summary_furthest_90536_99878.csv\")\n",
    "summaries32 = pd.read_csv(f\"summaries/theshold_k_3_baseline2_summary_furthest_90536_99878.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6518aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0018b80",
   "metadata": {},
   "source": [
    "# Extract Meta-Level Information from two contrastive Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403230a8",
   "metadata": {},
   "source": [
    "* site_id\n",
    "* Length First: Length of the previous version\n",
    "* Length Last: Lenght of latter version\n",
    "* Length Difference: The Difference between the two version (Last - First)\n",
    "* Years apart: Number of years between the publication of the two policies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab42516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meta(sites, df):\n",
    "    len_deltas = []\n",
    "    len_first = []\n",
    "    len_last = []\n",
    "    year_deltas = []\n",
    "    for i in range(len(sites)):\n",
    "\n",
    "        site_id = sites[i]\n",
    "\n",
    "        # sort first by year, then by phase\n",
    "        data = create_data(df.sort_values(by=['year', 'phase']), site_id)\n",
    "        \n",
    "        # extract 1st element\n",
    "        first = data.iloc[0]\n",
    "\n",
    "        # extract last element\n",
    "        last = data.iloc[-1]\n",
    "\n",
    "        len_delta = last.length - first.length\n",
    "        \n",
    "        len_first.append(first.length)\n",
    "        \n",
    "        len_last.append(last.length)\n",
    "        \n",
    "        len_deltas.append(len_delta)\n",
    "\n",
    "        year_delta = last.year - first.year\n",
    "        \n",
    "        year_deltas.append(year_delta)\n",
    "        \n",
    "    meta_data = pd.DataFrame({\"site_id\": sites,\n",
    "                              \"Length First\": len_first,\n",
    "                              \"Length Last\": len_last,\n",
    "                              \"Length Difference\": len_deltas, \n",
    "                              \"Years apart\": year_deltas})\n",
    "    \n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeecd97",
   "metadata": {},
   "source": [
    "# Manual Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d08dc",
   "metadata": {},
   "source": [
    "### Policy Ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f7c69",
   "metadata": {},
   "source": [
    "### Dictonary of manual Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe016bc",
   "metadata": {},
   "source": [
    "# Clean Data the same way as the algorithm does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de62fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "def remove_punctuation(text, symbols=string.punctuation):\n",
    "    return \"\".join([char for char in text if char not in symbols])\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db3dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(string):\n",
    "    string = remove_punctuation(string)\n",
    "    words_to_use = []\n",
    "    for word in nltk.word_tokenize(string):\n",
    "        if word not in stop_words:\n",
    "            words_to_use.append(cleaning_func(word))\n",
    "        \n",
    "    return \" \".join(words_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6d164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = {site: [process_text(word) for word in words] for site, words in manual.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0edff",
   "metadata": {},
   "source": [
    "# Create a DataFrame that describes the Manual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65443eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_manual(manual, compare=\"pipeline\", typ=\"manual\", path = \"dataframes\"):\n",
    "    f1s = []\n",
    "    precs = []\n",
    "    recalls = []\n",
    "    overlaps = []\n",
    "    \n",
    "    num_manual = []\n",
    "    stemmer = PorterStemmer()\n",
    "    sites = list(manual.keys())\n",
    "    \n",
    "    for site in sites:\n",
    "        \n",
    "        kws = manual[site]\n",
    "        \n",
    "        kws_hat = list(pd.read_csv(f\"{path}/{typ}_{compare}_keywords_{site}.csv\").keyword)\n",
    "        \n",
    "        kws = [stemmer.stem(kw) for kw in kws]\n",
    "\n",
    "        kws_hat = [stemmer.stem(str(kw_hat)) for kw_hat in kws_hat][:max(len(kws), 10)]\n",
    "        \n",
    "        overlap = summary.number_of_overlaps(set(kws), set(kws_hat))\n",
    "        \n",
    "        recall = overlap / max(1, len(kws_hat))\n",
    "\n",
    "        precision = overlap / max(1, len(kws))\n",
    "\n",
    "        f1 =  2 * (precision * recall) / max(1, precision + recall)\n",
    "        \n",
    "        f1s.append(f1)\n",
    "        precs.append(precision)\n",
    "        recalls.append(recall)\n",
    "        overlaps.append(overlap)\n",
    "        num_manual.append(len(kws))\n",
    "        \n",
    "    summary_frame = pd.DataFrame({'site_id': [int(site) for site in sites], \n",
    "                                  'f1': f1s, 'precision': precs,\n",
    "                                  'recall': recalls, '#overlaps': overlaps,\n",
    "                                 '#manual keywords': num_manual})\n",
    "    \n",
    "    return summary_frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd0cd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>#overlaps</th>\n",
       "      <th>#manual keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.518951</td>\n",
       "      <td>0.626759</td>\n",
       "      <td>0.493696</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>9.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.206458</td>\n",
       "      <td>0.230334</td>\n",
       "      <td>0.155058</td>\n",
       "      <td>1.912241</td>\n",
       "      <td>3.161223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1  precision     recall  #overlaps  #manual keywords\n",
       "count  25.000000  25.000000  25.000000  25.000000         25.000000\n",
       "mean    0.518951   0.626759   0.493696   5.360000          9.080000\n",
       "std     0.206458   0.230334   0.155058   1.912241          3.161223\n",
       "min     0.025000   0.125000   0.100000   1.000000          4.000000\n",
       "25%     0.367347   0.500000   0.400000   4.000000          7.000000\n",
       "50%     0.555556   0.625000   0.500000   5.000000          8.000000\n",
       "75%     0.666667   0.750000   0.600000   6.000000         10.000000\n",
       "max     0.823529   1.000000   0.727273   9.000000         17.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_df = evaluate_manual(manual, compare=\"pipeline\", typ=\"standard\")\n",
    "manual_df.drop(\"site_id\", axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e6a77a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>#overlaps</th>\n",
       "      <th>#manual keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.491599</td>\n",
       "      <td>0.572870</td>\n",
       "      <td>0.488743</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>9.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.203585</td>\n",
       "      <td>0.192592</td>\n",
       "      <td>0.140399</td>\n",
       "      <td>1.785165</td>\n",
       "      <td>3.049950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.358503</td>\n",
       "      <td>0.432540</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1  precision     recall  #overlaps  #manual keywords\n",
       "count  14.000000  14.000000  14.000000  14.000000         14.000000\n",
       "mean    0.491599   0.572870   0.488743   5.428571          9.928571\n",
       "std     0.203585   0.192592   0.140399   1.785165          3.049950\n",
       "min     0.080000   0.200000   0.200000   2.000000          6.000000\n",
       "25%     0.358503   0.432540   0.407143   5.000000          8.000000\n",
       "50%     0.555556   0.625000   0.500000   5.500000          9.000000\n",
       "75%     0.657895   0.744318   0.600000   6.000000         10.750000\n",
       "max     0.727273   0.833333   0.727273   9.000000         17.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be99ebc1",
   "metadata": {},
   "source": [
    "\n",
    "### Merge together the Summary DataFrame and the Meta Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(summary, meta, on=\"site_id\"):\n",
    "    summary.rename(columns={\"Site\": on}, inplace=True)\n",
    "\n",
    "    return meta.merge(summary, on=on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4678800",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_meta = create_meta(policy_ids, df)\n",
    "\n",
    "man0 = merge_dfs(manual_df0, man_meta)\n",
    "base01= merge_dfs(summaries01, man_meta)\n",
    "base02 = merge_dfs(summaries02, man_meta)\n",
    "man1 = merge_dfs(manual_df1, man_meta)\n",
    "base11= merge_dfs(summaries11, man_meta)\n",
    "base12 = merge_dfs(summaries12, man_meta)\n",
    "\n",
    "man2 = merge_dfs(manual_df2, man_meta)\n",
    "base21= merge_dfs(summaries21, man_meta)\n",
    "base22 = merge_dfs(summaries22, man_meta)\n",
    "man3 = merge_dfs(manual_df3, man_meta)\n",
    "base31= merge_dfs(summaries31, man_meta)\n",
    "base32 = merge_dfs(summaries32, man_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca744524",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_meta = create_meta(all_usefull_ids[1000:2000], df)\n",
    "summary1 = merge_dfs(summary1, man_meta)\n",
    "summary2 = merge_dfs(summary2, man_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8408bc",
   "metadata": {},
   "source": [
    "# Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(col, df, t):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "    \n",
    "    fig.suptitle(f\"{col} for {t} with respect to Difference in Length and Number of Years apart\", fontsize=16)\n",
    "    \n",
    "    df.sort_values(by=[\"Length Difference\"], inplace=True)\n",
    "    ax1.plot(df[\"Length Difference\"], df[col])\n",
    "    \n",
    "    ax1.set_xlabel(\"Difference in Length between old and new version\")\n",
    "    ax1.set_ylabel(col)\n",
    "    \n",
    "    df.sort_values(by=[\"Years apart\"], inplace=True)\n",
    "    ax2.plot(df[\"Years apart\"], df[col])\n",
    "    \n",
    "    ax2.set_xlabel(\"Number of Years apart\")\n",
    "    ax2.set_ylabel(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda39f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dists_base(m1, m2, m3, m4,column):\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15,5))\n",
    "    \n",
    "\n",
    "    m1[column].hist(ax=ax1)\n",
    "    ax1.set_title(f'{column} gamma 0.5')\n",
    "\n",
    "    m2[column].hist(ax=ax2)\n",
    "    ax2.set_title(f'{column} gamma 0.6')\n",
    "    \n",
    "    m3[column].hist(ax=ax3)\n",
    "    ax3.set_title(f'{column} gamma 0.7')\n",
    "    \n",
    "    m4[column].hist(ax=ax4)\n",
    "    ax4.set_title(f'{column} gamma 0.8')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4124b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dists(m1,m2,manual,column):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "    \n",
    "\n",
    "    m1[column].hist(ax=ax1)\n",
    "    ax1.set_title(f'{column} Distribution for Baseline 1')\n",
    "\n",
    "    m2[column].hist(ax=ax2)\n",
    "    ax2.set_title(f'{column} Distribution for Baseline 2')\n",
    "    \n",
    "    manual[column].hist(ax=ax3)\n",
    "    ax3.set_title(f'{column} Distribution for Manually Annotated Data')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26357c85",
   "metadata": {},
   "source": [
    "## Inspect the Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745aa39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(\"Precision\", summary1, \"Baseline 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb75a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(\"#overlaps\", summary2, \"baseline 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(\"Precision\", base01, \"baseline 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d3d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(\"#overlaps\", base01, \"baseline 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2139050",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists(summary1, summary2, summary1, \"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46169dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists(man0, man1, man2, \"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88db18",
   "metadata": {},
   "source": [
    "# Baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97063599",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists_base(base01, base11, base21, base31, \"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists_base(base01, base11, base21, base31, \"#overlaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists_base(base01, base11, base21, base31, \"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists_base(base01, base11, base21, base31, \"F1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb3d2f",
   "metadata": {},
   "source": [
    "# Baseline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccd472",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists_base(base02, base12, base22, base32, \"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92bb7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists_base(base02, base12, base22, base32, \"#overlaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists_base(base02, base12, base22, base32, \"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ca6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists_base(base02, base12, base22, base32, \"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965986a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4e9fc5",
   "metadata": {},
   "source": [
    "# Inspect the Number of Overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6174095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(\"#overlaps\", man, \"Manually Annotated Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38872088",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(\"#overlaps\", base1, \"baseline 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b49ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(\"#overlaps\", base2, \"baseline 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists(base1, base2, man, \"#overlaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b627c6",
   "metadata": {},
   "source": [
    "# News Revision Articles Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a9dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"news_ids.pkl\", \"rb\") as file:\n",
    "    # read list from file\n",
    "    news_ids = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab43c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_base_summaries1 = pd.read_csv(f\"summaries/baseline1_summary_furthest_16170_8150.csv\")\n",
    "news_base_summaries2 = pd.read_csv(f\"summaries/baseline2_summary_furthest_16170_8150.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_news = {\n",
    "    \"17348\": [\"computer screen\", \"soon\", \"expand\"],\n",
    "\n",
    "  \"17238\": [\"68-year-old\", \"former Republican\"],\n",
    "\n",
    "  \"16832\": [\"confetti-covered\", \"halftime\", \"Wolverines beat\", \"Florida\", \"Wolverines\"],\n",
    "\n",
    "  \"16170\": [\"tweeting\", \"Mainstream Media\", \"mocked\"],\n",
    "\n",
    "  \"16635\": [\"New York\", \"City Council\", \"Council members\", \"investigation\", \"previous landord\",\n",
    "            \"Kushner Cos\"],\n",
    "    \n",
    "  \"17982\": [\"allegiance\"],\n",
    "\n",
    "  \"2424\": [\"reckless overprescribing\", \"overprescribing\", \"combat misuse\", \"abuse\"],\n",
    "\n",
    "  \"17133\": [\"other\", \"online panel\", \"landline phones\", \"interviews\"],\n",
    "     \n",
    "  \"16112\": [\"Lulu\", \"dance class\", \"District Attorney\", \"Courtney Groves\", \"forcefully\",\n",
    "           \"forcefully shaking\", \"stared straight\", \"yelled angrily\", \"severe mental\",\n",
    "            \"mental distress\"],\n",
    "\n",
    "  \"17313\": [\"Investigators\", \"bank records\", \"communications\", \"Trump campaign\", \"taxi\", \"taxi industry\",\n",
    "            \"medallions\", \"Ukrainin-born\",  \"Taxi King\"],\n",
    "\n",
    "\n",
    "  \"7032\": [\"8:35 p.m.\", \"Andrew McCabe\", \"Alice Fisher\", \"assitant attorney\", \n",
    "            \"Justice Department's\"],\n",
    "\n",
    "  \"16687\":  [\"son-in-law\", \"Jared Kushner\", \"Jared Greenblatt\",\"Mideast peace\", \"peace plan\", \"Prince\",\n",
    "              \"Middle East\"],\n",
    "            \n",
    "  \"17736\": [\"DNA match\", \"police officer\", \"Golden State\", \"State Killer\", \"DeAngelo\",\n",
    "            \"emerging technology\", \"screaming\"], \n",
    "\n",
    "  \"6343\": [\"Christian-Muslim unity\", \"minority Christians\", \"military-run stadium\"],\n",
    "\n",
    "  \"16159\": [\"the party\", \"European Union\", \"Sen.Ben Sasse\", \"R-Neb\", \"Senate leader\", \"Senate\"],\n",
    "\n",
    "  \"16726\": [\"major breach\", \"cnn interview\", \"testify\",  \"before congress\", \"SCL Group\", \"David Carroll\"],\n",
    "\n",
    "  \"17970\": [\"television station\", \"KHON\", \"magma reservoir\", \"ground cracks\", \"457 meters\", \n",
    "            \"magnitude 5.0\", \"earthquake\"],\n",
    "\n",
    "  \"16226\": [\"holding trophy\", \"statuete\", \"arrested\", \"Police\", \"social media\", \"Facebook video\", \n",
    "            \"photographer\"], \n",
    "\n",
    "  \"3299\": [\"CIA\", \"Capitol\"],\n",
    "\n",
    "  \"8150\": [\"Facebook photos\", \"congressional baseball\", \"practice\", \"Judge\",\n",
    "           \"Robin Meriweather\", \"forensic screening\", \"mental health\", \"trial\", \"flood room\"] \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_news = {site: [process_text(word) for word in words] for site, words in manual_news.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe350099",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_news_df = evaluate_manual(manual_news, typ=\"news\", path=\"manual\")\n",
    "manual_news_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5597125",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_news = sqlite3.connect('../datasets/ap-matched-sentences.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = news_processing.doc_level_stats(8150, conn_news)\n",
    "doc.num_split.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065efc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meta_news(sites, conn_news):\n",
    "    sentence_counts_first = []\n",
    "    \n",
    "    sentence_counts_last = []\n",
    "    \n",
    "    diff_sentence_counts = []\n",
    "    \n",
    "    total_merges = []\n",
    "    \n",
    "    total_splits = []\n",
    "    \n",
    "    total_refactors = []\n",
    "    \n",
    "    total_additions = []\n",
    "    \n",
    "    total_deletions = []\n",
    "    \n",
    "    for i in range(len(sites)):\n",
    "\n",
    "        site_id = sites[i]\n",
    "\n",
    "        doc_stats = news_processing.doc_level_stats(site_id, conn_news)\n",
    "        \n",
    "        # extract 1st element\n",
    "        first = doc_stats.iloc[0]\n",
    "\n",
    "        # extract last element\n",
    "        last = doc_stats.iloc[-1]\n",
    "        \n",
    "        # Number of Sentences in each version\n",
    "        num_sentences_first = first.num_sentences_x\n",
    "        \n",
    "        num_sentences_last = last.num_sentences_y\n",
    "        \n",
    "        # Difference of the two counts\n",
    "        diff_sentence_count = num_sentences_last - num_sentences_first\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Fill up lists -------------\n",
    "        sentence_counts_first.append(num_sentences_first)\n",
    "        \n",
    "        sentence_counts_last.append(num_sentences_last)\n",
    "        \n",
    "        diff_sentence_counts.append(diff_sentence_count)\n",
    "        \n",
    "        # Total number of splits and merges from version 1 -> -1\n",
    "        total_merges.append(doc_stats.num_merged.sum())\n",
    "        \n",
    "        total_splits.append(doc_stats.num_split.sum())\n",
    "        \n",
    "        total_refactors.append(doc_stats.num_refactors.sum())\n",
    "        \n",
    "        total_additions.append(doc_stats.num_added.sum())\n",
    "        \n",
    "        total_deletions.append(doc_stats.num_deleted.sum())\n",
    "        \n",
    "    meta_data = pd.DataFrame({\"site_id\": sites,\n",
    "                              \"#sentences former\": sentence_counts_first,\n",
    "                              \"#sentences latter\": sentence_counts_last,\n",
    "                              \"#sentence Difference\": diff_sentence_counts, \n",
    "                              \"#splits\": total_splits,\n",
    "                              \"#merges\": total_merges,\n",
    "                              \"#refactors\": total_refactors,\n",
    "                              \"#additions\": total_additions,\n",
    "                              \"#deletions\": total_deletions})\n",
    "    \n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_news = create_meta_news(news_ids, conn_news)\n",
    "meta_news.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3003d4",
   "metadata": {},
   "source": [
    "## Merge Stats and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_news_df = merge_dfs(manual_news_df, meta_news)\n",
    "base1_news_df = merge_dfs(news_base_summaries1, meta_news)\n",
    "base2_news_df = merge_dfs(news_base_summaries2, meta_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_against_stats(col, df, t):\n",
    "    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(ncols=3,\n",
    "                                                       nrows=2,\n",
    "                                                       figsize=(16,8))\n",
    "    \n",
    "    fig.suptitle(f\"{col} for {t}\", fontsize=16)\n",
    "    # axis 1 - #sentence Difference\n",
    "    df.sort_values(by=[\"#sentence Difference\"], inplace=True)\n",
    "    ax1.plot(df[\"#sentence Difference\"], df[col])\n",
    "    \n",
    "    ax1.set_xlabel(\"Difference in #sentence between old and new version\")\n",
    "    ax1.set_ylabel(col)\n",
    "    \n",
    "    # axis 2 - #splits\n",
    "    df.sort_values(by=[\"#splits\"], inplace=True)\n",
    "    ax2.plot(df[\"#splits\"], df[col])\n",
    "    \n",
    "    ax2.set_xlabel(\"Total Number of Intermediate splits\")\n",
    "    ax2.set_ylabel(col)\n",
    "    \n",
    "    # axis 3 - #merges\n",
    "    df.sort_values(by=[\"#merges\"], inplace=True)\n",
    "    ax3.plot(df[\"#merges\"], df[col])\n",
    "    \n",
    "    ax3.set_xlabel(\"Total Number of Intermediate merges\")\n",
    "    ax3.set_ylabel(col)\n",
    "    \n",
    "    # axis 4 - #refactors\n",
    "    df.sort_values(by=[\"#refactors\"], inplace=True)\n",
    "    ax4.plot(df[\"#refactors\"], df[col])\n",
    "    \n",
    "    ax4.set_xlabel(\"Total Number of Intermediate refactors\")\n",
    "    ax4.set_ylabel(col)\n",
    "    \n",
    "    # axis 5 - #additions\n",
    "    df.sort_values(by=[\"#additions\"], inplace=True)\n",
    "    ax5.plot(df[\"#additions\"], df[col])\n",
    "    \n",
    "    ax5.set_xlabel(\"Total Number of Intermediate additions\")\n",
    "    ax5.set_ylabel(col)\n",
    "    \n",
    "    # axis 6 - #deletions\n",
    "    df.sort_values(by=[\"#deletions\"], inplace=True)\n",
    "    ax6.plot(df[\"#deletions\"], df[col])\n",
    "    \n",
    "    ax6.set_xlabel(\"Total Number of Intermediate deletions\")\n",
    "    ax6.set_ylabel(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e5087",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_against_stats(\"#overlaps\", man_news_df, \"Manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba20553",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_against_stats(\"#overlaps\", base2_news_df, \"Baseline 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47600108",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists(base1_news_df, base2_news_df, man_news_df, \"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dists(base1_news_df, base2_news_df, man_news_df, \"#overlaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base1_news_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3a6366",
   "metadata": {},
   "source": [
    "# Named Entity Recogintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3439d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the required data files\n",
    "\n",
    "# Tokenize the text\n",
    "text = \"Mark works at Apple and John are eating an apple in Mountain View.\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Part-of-speech tag the tokens\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "# Use the Named Entity Chunker to extract named entities\n",
    "chunker = nltk.chunk.ne_chunk(pos_tags)\n",
    "\n",
    "# Print the named entities\n",
    "for chunk in chunker:\n",
    "    if hasattr(chunk, \"label\"):\n",
    "        print(chunk.label(), \" \".join(c[0] for c in chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbeca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce177b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
